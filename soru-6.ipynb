{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('cure_the_princess_train.csv')\n",
    "val_data = pd.read_csv('cure_the_princess_validation.csv')\n",
    "test_data = pd.read_csv('cure_the_princess_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_data_np = train_data.to_numpy()\n",
    "val_data_np = val_data.to_numpy()\n",
    "test_data_np = test_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "train_inputs = torch.from_numpy(train_data_np[:, :13]).float().to(device)\n",
    "train_labels = torch.from_numpy(train_data_np[:, 13]).long().to(device)\n",
    "\n",
    "val_inputs = torch.from_numpy(val_data_np[:, :13]).float().to(device)\n",
    "val_labels = torch.from_numpy(val_data_np[:, 13]).long().to(device)\n",
    "\n",
    "test_inputs = torch.from_numpy(test_data_np[:, :13]).float().to(device)\n",
    "test_labels = torch.from_numpy(test_data_np[:, 13]).long().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_dataset = TensorDataset(train_inputs, train_labels)\n",
    "val_dataset = TensorDataset(val_inputs, val_labels)\n",
    "test_dataset = TensorDataset(test_inputs, test_labels)\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "torch.manual_seed(190401055)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden_layer_1 = nn.Linear(13, 100)\n",
    "        self.hidden_layer_2 = nn.Linear(100, 50)\n",
    "        self.output_layer = nn.Linear(50, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.hidden_layer_1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.hidden_layer_2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.sigmoid(self.output_layer(x))\n",
    "        return x\n",
    "\n",
    "model = MLP().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000, Train Loss: 1.0082, Val Loss: 0.6618, Patience: 0\n",
      "Epoch 2/2000, Train Loss: 0.8296, Val Loss: 0.6592, Patience: 0\n",
      "Epoch 3/2000, Train Loss: 0.7666, Val Loss: 0.6570, Patience: 0\n",
      "Epoch 4/2000, Train Loss: 0.7462, Val Loss: 0.6596, Patience: 1\n",
      "Epoch 5/2000, Train Loss: 0.7019, Val Loss: 0.6638, Patience: 2\n",
      "Epoch 6/2000, Train Loss: 0.6923, Val Loss: 0.6615, Patience: 3\n",
      "Epoch 7/2000, Train Loss: 0.7044, Val Loss: 0.6616, Patience: 4\n",
      "Epoch 8/2000, Train Loss: 0.6975, Val Loss: 0.6653, Patience: 5\n",
      "Epoch 9/2000, Train Loss: 0.6948, Val Loss: 0.6639, Patience: 6\n",
      "Epoch 10/2000, Train Loss: 0.6900, Val Loss: 0.6676, Patience: 7\n",
      "Epoch 11/2000, Train Loss: 0.6904, Val Loss: 0.6681, Patience: 8\n",
      "Epoch 12/2000, Train Loss: 0.6877, Val Loss: 0.6646, Patience: 9\n",
      "Epoch 13/2000, Train Loss: 0.6955, Val Loss: 0.6629, Patience: 10\n",
      "Epoch 14/2000, Train Loss: 0.6813, Val Loss: 0.6632, Patience: 11\n",
      "Epoch 15/2000, Train Loss: 0.6904, Val Loss: 0.6630, Patience: 12\n",
      "Epoch 16/2000, Train Loss: 0.6732, Val Loss: 0.6593, Patience: 13\n",
      "Epoch 17/2000, Train Loss: 0.6715, Val Loss: 0.6579, Patience: 14\n",
      "Epoch 18/2000, Train Loss: 0.6668, Val Loss: 0.6535, Patience: 0\n",
      "Epoch 19/2000, Train Loss: 0.6754, Val Loss: 0.6534, Patience: 0\n",
      "Epoch 20/2000, Train Loss: 0.6732, Val Loss: 0.6542, Patience: 1\n",
      "Epoch 21/2000, Train Loss: 0.6559, Val Loss: 0.6470, Patience: 0\n",
      "Epoch 22/2000, Train Loss: 0.6697, Val Loss: 0.6467, Patience: 0\n",
      "Epoch 23/2000, Train Loss: 0.6710, Val Loss: 0.6465, Patience: 0\n",
      "Epoch 24/2000, Train Loss: 0.6642, Val Loss: 0.6464, Patience: 0\n",
      "Epoch 25/2000, Train Loss: 0.6666, Val Loss: 0.6430, Patience: 0\n",
      "Epoch 26/2000, Train Loss: 0.6593, Val Loss: 0.6388, Patience: 0\n",
      "Epoch 27/2000, Train Loss: 0.6576, Val Loss: 0.6359, Patience: 0\n",
      "Epoch 28/2000, Train Loss: 0.6603, Val Loss: 0.6339, Patience: 0\n",
      "Epoch 29/2000, Train Loss: 0.6584, Val Loss: 0.6353, Patience: 1\n",
      "Epoch 30/2000, Train Loss: 0.6461, Val Loss: 0.6283, Patience: 0\n",
      "Epoch 31/2000, Train Loss: 0.6424, Val Loss: 0.6225, Patience: 0\n",
      "Epoch 32/2000, Train Loss: 0.6454, Val Loss: 0.6230, Patience: 1\n",
      "Epoch 33/2000, Train Loss: 0.6672, Val Loss: 0.6260, Patience: 2\n",
      "Epoch 34/2000, Train Loss: 0.6480, Val Loss: 0.6226, Patience: 3\n",
      "Epoch 35/2000, Train Loss: 0.6399, Val Loss: 0.6165, Patience: 0\n",
      "Epoch 36/2000, Train Loss: 0.6548, Val Loss: 0.6167, Patience: 1\n",
      "Epoch 37/2000, Train Loss: 0.6467, Val Loss: 0.6101, Patience: 0\n",
      "Epoch 38/2000, Train Loss: 0.6608, Val Loss: 0.6148, Patience: 1\n",
      "Epoch 39/2000, Train Loss: 0.6544, Val Loss: 0.6152, Patience: 2\n",
      "Epoch 40/2000, Train Loss: 0.6479, Val Loss: 0.6118, Patience: 3\n",
      "Epoch 41/2000, Train Loss: 0.6463, Val Loss: 0.6088, Patience: 0\n",
      "Epoch 42/2000, Train Loss: 0.6449, Val Loss: 0.6059, Patience: 0\n",
      "Epoch 43/2000, Train Loss: 0.6329, Val Loss: 0.6014, Patience: 0\n",
      "Epoch 44/2000, Train Loss: 0.6496, Val Loss: 0.6009, Patience: 0\n",
      "Epoch 45/2000, Train Loss: 0.6247, Val Loss: 0.5936, Patience: 0\n",
      "Epoch 46/2000, Train Loss: 0.6175, Val Loss: 0.5870, Patience: 0\n",
      "Epoch 47/2000, Train Loss: 0.6367, Val Loss: 0.5844, Patience: 0\n",
      "Epoch 48/2000, Train Loss: 0.6402, Val Loss: 0.5803, Patience: 0\n",
      "Epoch 49/2000, Train Loss: 0.6368, Val Loss: 0.5762, Patience: 0\n",
      "Epoch 50/2000, Train Loss: 0.6325, Val Loss: 0.5757, Patience: 0\n",
      "Epoch 51/2000, Train Loss: 0.6350, Val Loss: 0.5722, Patience: 0\n",
      "Epoch 52/2000, Train Loss: 0.6214, Val Loss: 0.5670, Patience: 0\n",
      "Epoch 53/2000, Train Loss: 0.6273, Val Loss: 0.5669, Patience: 0\n",
      "Epoch 54/2000, Train Loss: 0.6166, Val Loss: 0.5629, Patience: 0\n",
      "Epoch 55/2000, Train Loss: 0.6329, Val Loss: 0.5641, Patience: 1\n",
      "Epoch 56/2000, Train Loss: 0.6272, Val Loss: 0.5643, Patience: 2\n",
      "Epoch 57/2000, Train Loss: 0.6097, Val Loss: 0.5621, Patience: 0\n",
      "Epoch 58/2000, Train Loss: 0.6017, Val Loss: 0.5537, Patience: 0\n",
      "Epoch 59/2000, Train Loss: 0.6031, Val Loss: 0.5473, Patience: 0\n",
      "Epoch 60/2000, Train Loss: 0.6028, Val Loss: 0.5406, Patience: 0\n",
      "Epoch 61/2000, Train Loss: 0.6001, Val Loss: 0.5372, Patience: 0\n",
      "Epoch 62/2000, Train Loss: 0.6091, Val Loss: 0.5376, Patience: 1\n",
      "Epoch 63/2000, Train Loss: 0.6048, Val Loss: 0.5315, Patience: 0\n",
      "Epoch 64/2000, Train Loss: 0.6128, Val Loss: 0.5321, Patience: 1\n",
      "Epoch 65/2000, Train Loss: 0.6064, Val Loss: 0.5295, Patience: 0\n",
      "Epoch 66/2000, Train Loss: 0.5909, Val Loss: 0.5266, Patience: 0\n",
      "Epoch 67/2000, Train Loss: 0.6022, Val Loss: 0.5196, Patience: 0\n",
      "Epoch 68/2000, Train Loss: 0.5980, Val Loss: 0.5201, Patience: 1\n",
      "Epoch 69/2000, Train Loss: 0.5964, Val Loss: 0.5194, Patience: 0\n",
      "Epoch 70/2000, Train Loss: 0.5876, Val Loss: 0.5153, Patience: 0\n",
      "Epoch 71/2000, Train Loss: 0.5830, Val Loss: 0.5120, Patience: 0\n",
      "Epoch 72/2000, Train Loss: 0.5733, Val Loss: 0.5075, Patience: 0\n",
      "Epoch 73/2000, Train Loss: 0.5778, Val Loss: 0.5035, Patience: 0\n",
      "Epoch 74/2000, Train Loss: 0.5850, Val Loss: 0.5025, Patience: 0\n",
      "Epoch 75/2000, Train Loss: 0.5886, Val Loss: 0.5052, Patience: 1\n",
      "Epoch 76/2000, Train Loss: 0.5775, Val Loss: 0.5008, Patience: 0\n",
      "Epoch 77/2000, Train Loss: 0.5830, Val Loss: 0.5002, Patience: 0\n",
      "Epoch 78/2000, Train Loss: 0.5808, Val Loss: 0.4954, Patience: 0\n",
      "Epoch 79/2000, Train Loss: 0.5631, Val Loss: 0.4865, Patience: 0\n",
      "Epoch 80/2000, Train Loss: 0.5836, Val Loss: 0.4887, Patience: 1\n",
      "Epoch 81/2000, Train Loss: 0.5604, Val Loss: 0.4836, Patience: 0\n",
      "Epoch 82/2000, Train Loss: 0.5592, Val Loss: 0.4760, Patience: 0\n",
      "Epoch 83/2000, Train Loss: 0.5735, Val Loss: 0.4758, Patience: 0\n",
      "Epoch 84/2000, Train Loss: 0.5570, Val Loss: 0.4747, Patience: 0\n",
      "Epoch 85/2000, Train Loss: 0.5641, Val Loss: 0.4719, Patience: 0\n",
      "Epoch 86/2000, Train Loss: 0.5384, Val Loss: 0.4638, Patience: 0\n",
      "Epoch 87/2000, Train Loss: 0.5648, Val Loss: 0.4587, Patience: 0\n",
      "Epoch 88/2000, Train Loss: 0.5656, Val Loss: 0.4586, Patience: 0\n",
      "Epoch 89/2000, Train Loss: 0.5444, Val Loss: 0.4576, Patience: 0\n",
      "Epoch 90/2000, Train Loss: 0.5473, Val Loss: 0.4544, Patience: 0\n",
      "Epoch 91/2000, Train Loss: 0.5430, Val Loss: 0.4489, Patience: 0\n",
      "Epoch 92/2000, Train Loss: 0.5505, Val Loss: 0.4504, Patience: 1\n",
      "Epoch 93/2000, Train Loss: 0.5380, Val Loss: 0.4454, Patience: 0\n",
      "Epoch 94/2000, Train Loss: 0.5328, Val Loss: 0.4411, Patience: 0\n",
      "Epoch 95/2000, Train Loss: 0.5233, Val Loss: 0.4354, Patience: 0\n",
      "Epoch 96/2000, Train Loss: 0.5443, Val Loss: 0.4382, Patience: 1\n",
      "Epoch 97/2000, Train Loss: 0.5367, Val Loss: 0.4394, Patience: 2\n",
      "Epoch 98/2000, Train Loss: 0.5485, Val Loss: 0.4384, Patience: 3\n",
      "Epoch 99/2000, Train Loss: 0.5481, Val Loss: 0.4416, Patience: 4\n",
      "Epoch 100/2000, Train Loss: 0.5211, Val Loss: 0.4363, Patience: 5\n",
      "Epoch 101/2000, Train Loss: 0.5265, Val Loss: 0.4314, Patience: 0\n",
      "Epoch 102/2000, Train Loss: 0.5163, Val Loss: 0.4244, Patience: 0\n",
      "Epoch 103/2000, Train Loss: 0.5169, Val Loss: 0.4161, Patience: 0\n",
      "Epoch 104/2000, Train Loss: 0.5046, Val Loss: 0.4113, Patience: 0\n",
      "Epoch 105/2000, Train Loss: 0.4982, Val Loss: 0.4056, Patience: 0\n",
      "Epoch 106/2000, Train Loss: 0.5159, Val Loss: 0.4067, Patience: 1\n",
      "Epoch 107/2000, Train Loss: 0.5078, Val Loss: 0.4057, Patience: 2\n",
      "Epoch 108/2000, Train Loss: 0.4900, Val Loss: 0.3984, Patience: 0\n",
      "Epoch 109/2000, Train Loss: 0.5135, Val Loss: 0.3966, Patience: 0\n",
      "Epoch 110/2000, Train Loss: 0.5001, Val Loss: 0.3969, Patience: 1\n",
      "Epoch 111/2000, Train Loss: 0.4884, Val Loss: 0.3918, Patience: 0\n",
      "Epoch 112/2000, Train Loss: 0.5028, Val Loss: 0.3900, Patience: 0\n",
      "Epoch 113/2000, Train Loss: 0.4815, Val Loss: 0.3826, Patience: 0\n",
      "Epoch 114/2000, Train Loss: 0.5113, Val Loss: 0.3866, Patience: 1\n",
      "Epoch 115/2000, Train Loss: 0.4796, Val Loss: 0.3787, Patience: 0\n",
      "Epoch 116/2000, Train Loss: 0.4777, Val Loss: 0.3738, Patience: 0\n",
      "Epoch 117/2000, Train Loss: 0.4832, Val Loss: 0.3726, Patience: 0\n",
      "Epoch 118/2000, Train Loss: 0.4823, Val Loss: 0.3680, Patience: 0\n",
      "Epoch 119/2000, Train Loss: 0.4847, Val Loss: 0.3680, Patience: 1\n",
      "Epoch 120/2000, Train Loss: 0.4785, Val Loss: 0.3644, Patience: 0\n",
      "Epoch 121/2000, Train Loss: 0.4734, Val Loss: 0.3610, Patience: 0\n",
      "Epoch 122/2000, Train Loss: 0.4714, Val Loss: 0.3579, Patience: 0\n",
      "Epoch 123/2000, Train Loss: 0.4678, Val Loss: 0.3577, Patience: 0\n",
      "Epoch 124/2000, Train Loss: 0.4559, Val Loss: 0.3507, Patience: 0\n",
      "Epoch 125/2000, Train Loss: 0.4621, Val Loss: 0.3444, Patience: 0\n",
      "Epoch 126/2000, Train Loss: 0.4567, Val Loss: 0.3425, Patience: 0\n",
      "Epoch 127/2000, Train Loss: 0.4537, Val Loss: 0.3406, Patience: 0\n",
      "Epoch 128/2000, Train Loss: 0.4485, Val Loss: 0.3397, Patience: 0\n",
      "Epoch 129/2000, Train Loss: 0.4938, Val Loss: 0.3442, Patience: 1\n",
      "Epoch 130/2000, Train Loss: 0.4656, Val Loss: 0.3453, Patience: 2\n",
      "Epoch 131/2000, Train Loss: 0.4576, Val Loss: 0.3381, Patience: 0\n",
      "Epoch 132/2000, Train Loss: 0.4402, Val Loss: 0.3324, Patience: 0\n",
      "Epoch 133/2000, Train Loss: 0.4561, Val Loss: 0.3324, Patience: 0\n",
      "Epoch 134/2000, Train Loss: 0.4745, Val Loss: 0.3352, Patience: 1\n",
      "Epoch 135/2000, Train Loss: 0.4556, Val Loss: 0.3376, Patience: 2\n",
      "Epoch 136/2000, Train Loss: 0.4559, Val Loss: 0.3344, Patience: 3\n",
      "Epoch 137/2000, Train Loss: 0.4509, Val Loss: 0.3313, Patience: 0\n",
      "Epoch 138/2000, Train Loss: 0.4344, Val Loss: 0.3287, Patience: 0\n",
      "Epoch 139/2000, Train Loss: 0.4538, Val Loss: 0.3281, Patience: 0\n",
      "Epoch 140/2000, Train Loss: 0.4616, Val Loss: 0.3253, Patience: 0\n",
      "Epoch 141/2000, Train Loss: 0.4390, Val Loss: 0.3233, Patience: 0\n",
      "Epoch 142/2000, Train Loss: 0.4345, Val Loss: 0.3145, Patience: 0\n",
      "Epoch 143/2000, Train Loss: 0.4389, Val Loss: 0.3171, Patience: 1\n",
      "Epoch 144/2000, Train Loss: 0.4360, Val Loss: 0.3155, Patience: 2\n",
      "Epoch 145/2000, Train Loss: 0.4142, Val Loss: 0.3059, Patience: 0\n",
      "Epoch 146/2000, Train Loss: 0.4355, Val Loss: 0.3076, Patience: 1\n",
      "Epoch 147/2000, Train Loss: 0.4219, Val Loss: 0.3051, Patience: 0\n",
      "Epoch 148/2000, Train Loss: 0.4308, Val Loss: 0.2997, Patience: 0\n",
      "Epoch 149/2000, Train Loss: 0.4161, Val Loss: 0.2971, Patience: 0\n",
      "Epoch 150/2000, Train Loss: 0.4223, Val Loss: 0.2972, Patience: 1\n",
      "Epoch 151/2000, Train Loss: 0.4227, Val Loss: 0.2937, Patience: 0\n",
      "Epoch 152/2000, Train Loss: 0.4169, Val Loss: 0.2940, Patience: 1\n",
      "Epoch 153/2000, Train Loss: 0.4099, Val Loss: 0.2912, Patience: 0\n",
      "Epoch 154/2000, Train Loss: 0.4073, Val Loss: 0.2874, Patience: 0\n",
      "Epoch 155/2000, Train Loss: 0.4098, Val Loss: 0.2884, Patience: 1\n",
      "Epoch 156/2000, Train Loss: 0.3955, Val Loss: 0.2829, Patience: 0\n",
      "Epoch 157/2000, Train Loss: 0.4126, Val Loss: 0.2870, Patience: 1\n",
      "Epoch 158/2000, Train Loss: 0.3985, Val Loss: 0.2820, Patience: 0\n",
      "Epoch 159/2000, Train Loss: 0.4056, Val Loss: 0.2804, Patience: 0\n",
      "Epoch 160/2000, Train Loss: 0.3935, Val Loss: 0.2754, Patience: 0\n",
      "Epoch 161/2000, Train Loss: 0.3952, Val Loss: 0.2745, Patience: 0\n",
      "Epoch 162/2000, Train Loss: 0.3800, Val Loss: 0.2693, Patience: 0\n",
      "Epoch 163/2000, Train Loss: 0.4151, Val Loss: 0.2688, Patience: 0\n",
      "Epoch 164/2000, Train Loss: 0.3989, Val Loss: 0.2700, Patience: 1\n",
      "Epoch 165/2000, Train Loss: 0.3880, Val Loss: 0.2726, Patience: 2\n",
      "Epoch 166/2000, Train Loss: 0.4283, Val Loss: 0.2804, Patience: 3\n",
      "Epoch 167/2000, Train Loss: 0.4036, Val Loss: 0.2764, Patience: 4\n",
      "Epoch 168/2000, Train Loss: 0.3978, Val Loss: 0.2750, Patience: 5\n",
      "Epoch 169/2000, Train Loss: 0.3985, Val Loss: 0.2724, Patience: 6\n",
      "Epoch 170/2000, Train Loss: 0.3723, Val Loss: 0.2679, Patience: 0\n",
      "Epoch 171/2000, Train Loss: 0.3791, Val Loss: 0.2631, Patience: 0\n",
      "Epoch 172/2000, Train Loss: 0.3817, Val Loss: 0.2610, Patience: 0\n",
      "Epoch 173/2000, Train Loss: 0.3841, Val Loss: 0.2600, Patience: 0\n",
      "Epoch 174/2000, Train Loss: 0.3705, Val Loss: 0.2594, Patience: 0\n",
      "Epoch 175/2000, Train Loss: 0.3957, Val Loss: 0.2610, Patience: 1\n",
      "Epoch 176/2000, Train Loss: 0.3850, Val Loss: 0.2620, Patience: 2\n",
      "Epoch 177/2000, Train Loss: 0.3752, Val Loss: 0.2616, Patience: 3\n",
      "Epoch 178/2000, Train Loss: 0.3908, Val Loss: 0.2603, Patience: 4\n",
      "Epoch 179/2000, Train Loss: 0.3593, Val Loss: 0.2567, Patience: 0\n",
      "Epoch 180/2000, Train Loss: 0.3729, Val Loss: 0.2560, Patience: 0\n",
      "Epoch 181/2000, Train Loss: 0.3665, Val Loss: 0.2518, Patience: 0\n",
      "Epoch 182/2000, Train Loss: 0.3640, Val Loss: 0.2501, Patience: 0\n",
      "Epoch 183/2000, Train Loss: 0.3405, Val Loss: 0.2442, Patience: 0\n",
      "Epoch 184/2000, Train Loss: 0.3727, Val Loss: 0.2466, Patience: 1\n",
      "Epoch 185/2000, Train Loss: 0.3644, Val Loss: 0.2471, Patience: 2\n",
      "Epoch 186/2000, Train Loss: 0.3701, Val Loss: 0.2462, Patience: 3\n",
      "Epoch 187/2000, Train Loss: 0.3493, Val Loss: 0.2440, Patience: 0\n",
      "Epoch 188/2000, Train Loss: 0.3601, Val Loss: 0.2405, Patience: 0\n",
      "Epoch 189/2000, Train Loss: 0.3565, Val Loss: 0.2414, Patience: 1\n",
      "Epoch 190/2000, Train Loss: 0.3702, Val Loss: 0.2432, Patience: 2\n",
      "Epoch 191/2000, Train Loss: 0.3551, Val Loss: 0.2392, Patience: 0\n",
      "Epoch 192/2000, Train Loss: 0.3478, Val Loss: 0.2405, Patience: 1\n",
      "Epoch 193/2000, Train Loss: 0.3661, Val Loss: 0.2426, Patience: 2\n",
      "Epoch 194/2000, Train Loss: 0.3577, Val Loss: 0.2397, Patience: 3\n",
      "Epoch 195/2000, Train Loss: 0.3475, Val Loss: 0.2369, Patience: 0\n",
      "Epoch 196/2000, Train Loss: 0.3410, Val Loss: 0.2349, Patience: 0\n",
      "Epoch 197/2000, Train Loss: 0.3559, Val Loss: 0.2377, Patience: 1\n",
      "Epoch 198/2000, Train Loss: 0.3421, Val Loss: 0.2378, Patience: 2\n",
      "Epoch 199/2000, Train Loss: 0.3410, Val Loss: 0.2381, Patience: 3\n",
      "Epoch 200/2000, Train Loss: 0.3435, Val Loss: 0.2353, Patience: 4\n",
      "Epoch 201/2000, Train Loss: 0.3325, Val Loss: 0.2332, Patience: 0\n",
      "Epoch 202/2000, Train Loss: 0.3576, Val Loss: 0.2325, Patience: 0\n",
      "Epoch 203/2000, Train Loss: 0.3636, Val Loss: 0.2362, Patience: 1\n",
      "Epoch 204/2000, Train Loss: 0.3646, Val Loss: 0.2347, Patience: 2\n",
      "Epoch 205/2000, Train Loss: 0.3323, Val Loss: 0.2338, Patience: 3\n",
      "Epoch 206/2000, Train Loss: 0.3440, Val Loss: 0.2350, Patience: 4\n",
      "Epoch 207/2000, Train Loss: 0.3455, Val Loss: 0.2330, Patience: 5\n",
      "Epoch 208/2000, Train Loss: 0.3347, Val Loss: 0.2309, Patience: 0\n",
      "Epoch 209/2000, Train Loss: 0.3317, Val Loss: 0.2257, Patience: 0\n",
      "Epoch 210/2000, Train Loss: 0.3324, Val Loss: 0.2263, Patience: 1\n",
      "Epoch 211/2000, Train Loss: 0.3412, Val Loss: 0.2284, Patience: 2\n",
      "Epoch 212/2000, Train Loss: 0.3488, Val Loss: 0.2272, Patience: 3\n",
      "Epoch 213/2000, Train Loss: 0.3263, Val Loss: 0.2264, Patience: 4\n",
      "Epoch 214/2000, Train Loss: 0.3324, Val Loss: 0.2241, Patience: 0\n",
      "Epoch 215/2000, Train Loss: 0.3234, Val Loss: 0.2238, Patience: 0\n",
      "Epoch 216/2000, Train Loss: 0.3407, Val Loss: 0.2229, Patience: 0\n",
      "Epoch 217/2000, Train Loss: 0.3296, Val Loss: 0.2227, Patience: 0\n",
      "Epoch 218/2000, Train Loss: 0.3315, Val Loss: 0.2227, Patience: 1\n",
      "Epoch 219/2000, Train Loss: 0.3328, Val Loss: 0.2216, Patience: 0\n",
      "Epoch 220/2000, Train Loss: 0.3291, Val Loss: 0.2205, Patience: 0\n",
      "Epoch 221/2000, Train Loss: 0.3111, Val Loss: 0.2181, Patience: 0\n",
      "Epoch 222/2000, Train Loss: 0.3398, Val Loss: 0.2210, Patience: 1\n",
      "Epoch 223/2000, Train Loss: 0.3307, Val Loss: 0.2201, Patience: 2\n",
      "Epoch 224/2000, Train Loss: 0.3206, Val Loss: 0.2210, Patience: 3\n",
      "Epoch 225/2000, Train Loss: 0.3035, Val Loss: 0.2177, Patience: 0\n",
      "Epoch 226/2000, Train Loss: 0.3393, Val Loss: 0.2190, Patience: 1\n",
      "Epoch 227/2000, Train Loss: 0.3135, Val Loss: 0.2178, Patience: 2\n",
      "Epoch 228/2000, Train Loss: 0.3018, Val Loss: 0.2152, Patience: 0\n",
      "Epoch 229/2000, Train Loss: 0.3271, Val Loss: 0.2192, Patience: 1\n",
      "Epoch 230/2000, Train Loss: 0.2975, Val Loss: 0.2170, Patience: 2\n",
      "Epoch 231/2000, Train Loss: 0.3124, Val Loss: 0.2178, Patience: 3\n",
      "Epoch 232/2000, Train Loss: 0.2990, Val Loss: 0.2138, Patience: 0\n",
      "Epoch 233/2000, Train Loss: 0.3168, Val Loss: 0.2138, Patience: 0\n",
      "Epoch 234/2000, Train Loss: 0.2941, Val Loss: 0.2117, Patience: 0\n",
      "Epoch 235/2000, Train Loss: 0.3230, Val Loss: 0.2124, Patience: 1\n",
      "Epoch 236/2000, Train Loss: 0.3139, Val Loss: 0.2141, Patience: 2\n",
      "Epoch 237/2000, Train Loss: 0.3252, Val Loss: 0.2134, Patience: 3\n",
      "Epoch 238/2000, Train Loss: 0.2967, Val Loss: 0.2103, Patience: 0\n",
      "Epoch 239/2000, Train Loss: 0.3124, Val Loss: 0.2107, Patience: 1\n",
      "Epoch 240/2000, Train Loss: 0.3031, Val Loss: 0.2090, Patience: 0\n",
      "Epoch 241/2000, Train Loss: 0.3130, Val Loss: 0.2080, Patience: 0\n",
      "Epoch 242/2000, Train Loss: 0.3307, Val Loss: 0.2107, Patience: 1\n",
      "Epoch 243/2000, Train Loss: 0.2885, Val Loss: 0.2094, Patience: 2\n",
      "Epoch 244/2000, Train Loss: 0.2954, Val Loss: 0.2077, Patience: 0\n",
      "Epoch 245/2000, Train Loss: 0.2839, Val Loss: 0.2060, Patience: 0\n",
      "Epoch 246/2000, Train Loss: 0.2973, Val Loss: 0.2064, Patience: 1\n",
      "Epoch 247/2000, Train Loss: 0.3071, Val Loss: 0.2062, Patience: 2\n",
      "Epoch 248/2000, Train Loss: 0.2974, Val Loss: 0.2056, Patience: 0\n",
      "Epoch 249/2000, Train Loss: 0.2969, Val Loss: 0.2055, Patience: 0\n",
      "Epoch 250/2000, Train Loss: 0.3019, Val Loss: 0.2026, Patience: 0\n",
      "Epoch 251/2000, Train Loss: 0.2956, Val Loss: 0.2033, Patience: 1\n",
      "Epoch 252/2000, Train Loss: 0.2885, Val Loss: 0.2025, Patience: 0\n",
      "Epoch 253/2000, Train Loss: 0.2980, Val Loss: 0.2021, Patience: 0\n",
      "Epoch 254/2000, Train Loss: 0.2967, Val Loss: 0.2028, Patience: 1\n",
      "Epoch 255/2000, Train Loss: 0.3190, Val Loss: 0.2034, Patience: 2\n",
      "Epoch 256/2000, Train Loss: 0.3042, Val Loss: 0.2025, Patience: 3\n",
      "Epoch 257/2000, Train Loss: 0.2856, Val Loss: 0.2005, Patience: 0\n",
      "Epoch 258/2000, Train Loss: 0.2954, Val Loss: 0.2020, Patience: 1\n",
      "Epoch 259/2000, Train Loss: 0.3011, Val Loss: 0.2042, Patience: 2\n",
      "Epoch 260/2000, Train Loss: 0.3048, Val Loss: 0.2029, Patience: 3\n",
      "Epoch 261/2000, Train Loss: 0.3019, Val Loss: 0.2023, Patience: 4\n",
      "Epoch 262/2000, Train Loss: 0.2840, Val Loss: 0.2008, Patience: 5\n",
      "Epoch 263/2000, Train Loss: 0.2690, Val Loss: 0.1992, Patience: 0\n",
      "Epoch 264/2000, Train Loss: 0.2950, Val Loss: 0.2006, Patience: 1\n",
      "Epoch 265/2000, Train Loss: 0.2863, Val Loss: 0.2007, Patience: 2\n",
      "Epoch 266/2000, Train Loss: 0.2964, Val Loss: 0.1995, Patience: 3\n",
      "Epoch 267/2000, Train Loss: 0.2883, Val Loss: 0.1998, Patience: 4\n",
      "Epoch 268/2000, Train Loss: 0.2846, Val Loss: 0.1978, Patience: 0\n",
      "Epoch 269/2000, Train Loss: 0.2707, Val Loss: 0.1969, Patience: 0\n",
      "Epoch 270/2000, Train Loss: 0.2697, Val Loss: 0.1953, Patience: 0\n",
      "Epoch 271/2000, Train Loss: 0.2896, Val Loss: 0.1966, Patience: 1\n",
      "Epoch 272/2000, Train Loss: 0.2759, Val Loss: 0.1955, Patience: 2\n",
      "Epoch 273/2000, Train Loss: 0.2907, Val Loss: 0.1960, Patience: 3\n",
      "Epoch 274/2000, Train Loss: 0.2686, Val Loss: 0.1964, Patience: 4\n",
      "Epoch 275/2000, Train Loss: 0.2721, Val Loss: 0.1950, Patience: 0\n",
      "Epoch 276/2000, Train Loss: 0.2899, Val Loss: 0.1951, Patience: 1\n",
      "Epoch 277/2000, Train Loss: 0.2948, Val Loss: 0.1966, Patience: 2\n",
      "Epoch 278/2000, Train Loss: 0.2684, Val Loss: 0.1949, Patience: 0\n",
      "Epoch 279/2000, Train Loss: 0.2857, Val Loss: 0.1950, Patience: 1\n",
      "Epoch 280/2000, Train Loss: 0.2969, Val Loss: 0.1963, Patience: 2\n",
      "Epoch 281/2000, Train Loss: 0.3003, Val Loss: 0.1969, Patience: 3\n",
      "Epoch 282/2000, Train Loss: 0.2711, Val Loss: 0.1949, Patience: 4\n",
      "Epoch 283/2000, Train Loss: 0.2867, Val Loss: 0.1964, Patience: 5\n",
      "Epoch 284/2000, Train Loss: 0.2860, Val Loss: 0.1941, Patience: 0\n",
      "Epoch 285/2000, Train Loss: 0.2875, Val Loss: 0.1930, Patience: 0\n",
      "Epoch 286/2000, Train Loss: 0.2656, Val Loss: 0.1934, Patience: 1\n",
      "Epoch 287/2000, Train Loss: 0.2963, Val Loss: 0.1947, Patience: 2\n",
      "Epoch 288/2000, Train Loss: 0.2697, Val Loss: 0.1929, Patience: 0\n",
      "Epoch 289/2000, Train Loss: 0.2907, Val Loss: 0.1926, Patience: 0\n",
      "Epoch 290/2000, Train Loss: 0.2603, Val Loss: 0.1900, Patience: 0\n",
      "Epoch 291/2000, Train Loss: 0.2882, Val Loss: 0.1916, Patience: 1\n",
      "Epoch 292/2000, Train Loss: 0.2802, Val Loss: 0.1910, Patience: 2\n",
      "Epoch 293/2000, Train Loss: 0.2759, Val Loss: 0.1898, Patience: 0\n",
      "Epoch 294/2000, Train Loss: 0.2724, Val Loss: 0.1896, Patience: 0\n",
      "Epoch 295/2000, Train Loss: 0.2559, Val Loss: 0.1882, Patience: 0\n",
      "Epoch 296/2000, Train Loss: 0.2750, Val Loss: 0.1880, Patience: 0\n",
      "Epoch 297/2000, Train Loss: 0.2887, Val Loss: 0.1882, Patience: 1\n",
      "Epoch 298/2000, Train Loss: 0.2728, Val Loss: 0.1872, Patience: 0\n",
      "Epoch 299/2000, Train Loss: 0.2582, Val Loss: 0.1854, Patience: 0\n",
      "Epoch 300/2000, Train Loss: 0.2571, Val Loss: 0.1857, Patience: 1\n",
      "Epoch 301/2000, Train Loss: 0.2709, Val Loss: 0.1869, Patience: 2\n",
      "Epoch 302/2000, Train Loss: 0.2799, Val Loss: 0.1880, Patience: 3\n",
      "Epoch 303/2000, Train Loss: 0.2652, Val Loss: 0.1865, Patience: 4\n",
      "Epoch 304/2000, Train Loss: 0.2491, Val Loss: 0.1856, Patience: 5\n",
      "Epoch 305/2000, Train Loss: 0.2675, Val Loss: 0.1853, Patience: 0\n",
      "Epoch 306/2000, Train Loss: 0.2654, Val Loss: 0.1857, Patience: 1\n",
      "Epoch 307/2000, Train Loss: 0.2780, Val Loss: 0.1861, Patience: 2\n",
      "Epoch 308/2000, Train Loss: 0.2494, Val Loss: 0.1842, Patience: 0\n",
      "Epoch 309/2000, Train Loss: 0.2719, Val Loss: 0.1846, Patience: 1\n",
      "Epoch 310/2000, Train Loss: 0.2605, Val Loss: 0.1833, Patience: 0\n",
      "Epoch 311/2000, Train Loss: 0.2589, Val Loss: 0.1830, Patience: 0\n",
      "Epoch 312/2000, Train Loss: 0.2524, Val Loss: 0.1829, Patience: 0\n",
      "Epoch 313/2000, Train Loss: 0.2522, Val Loss: 0.1826, Patience: 0\n",
      "Epoch 314/2000, Train Loss: 0.2511, Val Loss: 0.1826, Patience: 1\n",
      "Epoch 315/2000, Train Loss: 0.2583, Val Loss: 0.1826, Patience: 2\n",
      "Epoch 316/2000, Train Loss: 0.2475, Val Loss: 0.1829, Patience: 3\n",
      "Epoch 317/2000, Train Loss: 0.2667, Val Loss: 0.1824, Patience: 0\n",
      "Epoch 318/2000, Train Loss: 0.2718, Val Loss: 0.1821, Patience: 0\n",
      "Epoch 319/2000, Train Loss: 0.2818, Val Loss: 0.1839, Patience: 1\n",
      "Epoch 320/2000, Train Loss: 0.2535, Val Loss: 0.1814, Patience: 0\n",
      "Epoch 321/2000, Train Loss: 0.2534, Val Loss: 0.1822, Patience: 1\n",
      "Epoch 322/2000, Train Loss: 0.2547, Val Loss: 0.1816, Patience: 2\n",
      "Epoch 323/2000, Train Loss: 0.2501, Val Loss: 0.1806, Patience: 0\n",
      "Epoch 324/2000, Train Loss: 0.2448, Val Loss: 0.1803, Patience: 0\n",
      "Epoch 325/2000, Train Loss: 0.2449, Val Loss: 0.1793, Patience: 0\n",
      "Epoch 326/2000, Train Loss: 0.2679, Val Loss: 0.1790, Patience: 0\n",
      "Epoch 327/2000, Train Loss: 0.2501, Val Loss: 0.1793, Patience: 1\n",
      "Epoch 328/2000, Train Loss: 0.2555, Val Loss: 0.1789, Patience: 0\n",
      "Epoch 329/2000, Train Loss: 0.2414, Val Loss: 0.1765, Patience: 0\n",
      "Epoch 330/2000, Train Loss: 0.2403, Val Loss: 0.1780, Patience: 1\n",
      "Epoch 331/2000, Train Loss: 0.2543, Val Loss: 0.1769, Patience: 2\n",
      "Epoch 332/2000, Train Loss: 0.2452, Val Loss: 0.1777, Patience: 3\n",
      "Epoch 333/2000, Train Loss: 0.2589, Val Loss: 0.1780, Patience: 4\n",
      "Epoch 334/2000, Train Loss: 0.2517, Val Loss: 0.1785, Patience: 5\n",
      "Epoch 335/2000, Train Loss: 0.2528, Val Loss: 0.1792, Patience: 6\n",
      "Epoch 336/2000, Train Loss: 0.2515, Val Loss: 0.1771, Patience: 7\n",
      "Epoch 337/2000, Train Loss: 0.2605, Val Loss: 0.1771, Patience: 8\n",
      "Epoch 338/2000, Train Loss: 0.2580, Val Loss: 0.1781, Patience: 9\n",
      "Epoch 339/2000, Train Loss: 0.2500, Val Loss: 0.1763, Patience: 0\n",
      "Epoch 340/2000, Train Loss: 0.2495, Val Loss: 0.1771, Patience: 1\n",
      "Epoch 341/2000, Train Loss: 0.2313, Val Loss: 0.1765, Patience: 2\n",
      "Epoch 342/2000, Train Loss: 0.2372, Val Loss: 0.1742, Patience: 0\n",
      "Epoch 343/2000, Train Loss: 0.2293, Val Loss: 0.1750, Patience: 1\n",
      "Epoch 344/2000, Train Loss: 0.2492, Val Loss: 0.1756, Patience: 2\n",
      "Epoch 345/2000, Train Loss: 0.2337, Val Loss: 0.1742, Patience: 0\n",
      "Epoch 346/2000, Train Loss: 0.2675, Val Loss: 0.1735, Patience: 0\n",
      "Epoch 347/2000, Train Loss: 0.2375, Val Loss: 0.1728, Patience: 0\n",
      "Epoch 348/2000, Train Loss: 0.2507, Val Loss: 0.1748, Patience: 1\n",
      "Epoch 349/2000, Train Loss: 0.2408, Val Loss: 0.1743, Patience: 2\n",
      "Epoch 350/2000, Train Loss: 0.2538, Val Loss: 0.1746, Patience: 3\n",
      "Epoch 351/2000, Train Loss: 0.2476, Val Loss: 0.1743, Patience: 4\n",
      "Epoch 352/2000, Train Loss: 0.2370, Val Loss: 0.1737, Patience: 5\n",
      "Epoch 353/2000, Train Loss: 0.2415, Val Loss: 0.1724, Patience: 0\n",
      "Epoch 354/2000, Train Loss: 0.2299, Val Loss: 0.1720, Patience: 0\n",
      "Epoch 355/2000, Train Loss: 0.2430, Val Loss: 0.1723, Patience: 1\n",
      "Epoch 356/2000, Train Loss: 0.2332, Val Loss: 0.1710, Patience: 0\n",
      "Epoch 357/2000, Train Loss: 0.2317, Val Loss: 0.1716, Patience: 1\n",
      "Epoch 358/2000, Train Loss: 0.2464, Val Loss: 0.1744, Patience: 2\n",
      "Epoch 359/2000, Train Loss: 0.2288, Val Loss: 0.1715, Patience: 3\n",
      "Epoch 360/2000, Train Loss: 0.2420, Val Loss: 0.1702, Patience: 0\n",
      "Epoch 361/2000, Train Loss: 0.2426, Val Loss: 0.1711, Patience: 1\n",
      "Epoch 362/2000, Train Loss: 0.2260, Val Loss: 0.1688, Patience: 0\n",
      "Epoch 363/2000, Train Loss: 0.2214, Val Loss: 0.1696, Patience: 1\n",
      "Epoch 364/2000, Train Loss: 0.2410, Val Loss: 0.1717, Patience: 2\n",
      "Epoch 365/2000, Train Loss: 0.2580, Val Loss: 0.1738, Patience: 3\n",
      "Epoch 366/2000, Train Loss: 0.2438, Val Loss: 0.1734, Patience: 4\n",
      "Epoch 367/2000, Train Loss: 0.2304, Val Loss: 0.1719, Patience: 5\n",
      "Epoch 368/2000, Train Loss: 0.2327, Val Loss: 0.1699, Patience: 6\n",
      "Epoch 369/2000, Train Loss: 0.2361, Val Loss: 0.1731, Patience: 7\n",
      "Epoch 370/2000, Train Loss: 0.2371, Val Loss: 0.1700, Patience: 8\n",
      "Epoch 371/2000, Train Loss: 0.2216, Val Loss: 0.1675, Patience: 0\n",
      "Epoch 372/2000, Train Loss: 0.2327, Val Loss: 0.1676, Patience: 1\n",
      "Epoch 373/2000, Train Loss: 0.2194, Val Loss: 0.1656, Patience: 0\n",
      "Epoch 374/2000, Train Loss: 0.2312, Val Loss: 0.1636, Patience: 0\n",
      "Epoch 375/2000, Train Loss: 0.2087, Val Loss: 0.1645, Patience: 1\n",
      "Epoch 376/2000, Train Loss: 0.2310, Val Loss: 0.1647, Patience: 2\n",
      "Epoch 377/2000, Train Loss: 0.2266, Val Loss: 0.1631, Patience: 0\n",
      "Epoch 378/2000, Train Loss: 0.2241, Val Loss: 0.1646, Patience: 1\n",
      "Epoch 379/2000, Train Loss: 0.2278, Val Loss: 0.1644, Patience: 2\n",
      "Epoch 380/2000, Train Loss: 0.2225, Val Loss: 0.1654, Patience: 3\n",
      "Epoch 381/2000, Train Loss: 0.2367, Val Loss: 0.1638, Patience: 4\n",
      "Epoch 382/2000, Train Loss: 0.2220, Val Loss: 0.1655, Patience: 5\n",
      "Epoch 383/2000, Train Loss: 0.2213, Val Loss: 0.1663, Patience: 6\n",
      "Epoch 384/2000, Train Loss: 0.2096, Val Loss: 0.1657, Patience: 7\n",
      "Epoch 385/2000, Train Loss: 0.2370, Val Loss: 0.1665, Patience: 8\n",
      "Epoch 386/2000, Train Loss: 0.2251, Val Loss: 0.1678, Patience: 9\n",
      "Epoch 387/2000, Train Loss: 0.2142, Val Loss: 0.1673, Patience: 10\n",
      "Epoch 388/2000, Train Loss: 0.2370, Val Loss: 0.1655, Patience: 11\n",
      "Epoch 389/2000, Train Loss: 0.2227, Val Loss: 0.1685, Patience: 12\n",
      "Epoch 390/2000, Train Loss: 0.2415, Val Loss: 0.1649, Patience: 13\n",
      "Epoch 391/2000, Train Loss: 0.2253, Val Loss: 0.1637, Patience: 14\n",
      "Epoch 392/2000, Train Loss: 0.2359, Val Loss: 0.1655, Patience: 15\n",
      "Epoch 393/2000, Train Loss: 0.2165, Val Loss: 0.1618, Patience: 0\n",
      "Epoch 394/2000, Train Loss: 0.2147, Val Loss: 0.1617, Patience: 0\n",
      "Epoch 395/2000, Train Loss: 0.2142, Val Loss: 0.1646, Patience: 1\n",
      "Epoch 396/2000, Train Loss: 0.2273, Val Loss: 0.1609, Patience: 0\n",
      "Epoch 397/2000, Train Loss: 0.2270, Val Loss: 0.1608, Patience: 0\n",
      "Epoch 398/2000, Train Loss: 0.2156, Val Loss: 0.1620, Patience: 1\n",
      "Epoch 399/2000, Train Loss: 0.2119, Val Loss: 0.1611, Patience: 2\n",
      "Epoch 400/2000, Train Loss: 0.2114, Val Loss: 0.1626, Patience: 3\n",
      "Epoch 401/2000, Train Loss: 0.2181, Val Loss: 0.1627, Patience: 4\n",
      "Epoch 402/2000, Train Loss: 0.2155, Val Loss: 0.1629, Patience: 5\n",
      "Epoch 403/2000, Train Loss: 0.2299, Val Loss: 0.1644, Patience: 6\n",
      "Epoch 404/2000, Train Loss: 0.2172, Val Loss: 0.1612, Patience: 7\n",
      "Epoch 405/2000, Train Loss: 0.2067, Val Loss: 0.1621, Patience: 8\n",
      "Epoch 406/2000, Train Loss: 0.2185, Val Loss: 0.1613, Patience: 9\n",
      "Epoch 407/2000, Train Loss: 0.2147, Val Loss: 0.1597, Patience: 0\n",
      "Epoch 408/2000, Train Loss: 0.2208, Val Loss: 0.1613, Patience: 1\n",
      "Epoch 409/2000, Train Loss: 0.2202, Val Loss: 0.1632, Patience: 2\n",
      "Epoch 410/2000, Train Loss: 0.2138, Val Loss: 0.1624, Patience: 3\n",
      "Epoch 411/2000, Train Loss: 0.2076, Val Loss: 0.1608, Patience: 4\n",
      "Epoch 412/2000, Train Loss: 0.2169, Val Loss: 0.1614, Patience: 5\n",
      "Epoch 413/2000, Train Loss: 0.2209, Val Loss: 0.1612, Patience: 6\n",
      "Epoch 414/2000, Train Loss: 0.2195, Val Loss: 0.1609, Patience: 7\n",
      "Epoch 415/2000, Train Loss: 0.2051, Val Loss: 0.1566, Patience: 0\n",
      "Epoch 416/2000, Train Loss: 0.2195, Val Loss: 0.1570, Patience: 1\n",
      "Epoch 417/2000, Train Loss: 0.2196, Val Loss: 0.1563, Patience: 0\n",
      "Epoch 418/2000, Train Loss: 0.2156, Val Loss: 0.1581, Patience: 1\n",
      "Epoch 419/2000, Train Loss: 0.2189, Val Loss: 0.1585, Patience: 2\n",
      "Epoch 420/2000, Train Loss: 0.2099, Val Loss: 0.1585, Patience: 3\n",
      "Epoch 421/2000, Train Loss: 0.2132, Val Loss: 0.1586, Patience: 4\n",
      "Epoch 422/2000, Train Loss: 0.2110, Val Loss: 0.1605, Patience: 5\n",
      "Epoch 423/2000, Train Loss: 0.2079, Val Loss: 0.1604, Patience: 6\n",
      "Epoch 424/2000, Train Loss: 0.2152, Val Loss: 0.1598, Patience: 7\n",
      "Epoch 425/2000, Train Loss: 0.2143, Val Loss: 0.1589, Patience: 8\n",
      "Epoch 426/2000, Train Loss: 0.2146, Val Loss: 0.1577, Patience: 9\n",
      "Epoch 427/2000, Train Loss: 0.2122, Val Loss: 0.1580, Patience: 10\n",
      "Epoch 428/2000, Train Loss: 0.2038, Val Loss: 0.1561, Patience: 0\n",
      "Epoch 429/2000, Train Loss: 0.1999, Val Loss: 0.1559, Patience: 0\n",
      "Epoch 430/2000, Train Loss: 0.2060, Val Loss: 0.1551, Patience: 0\n",
      "Epoch 431/2000, Train Loss: 0.2080, Val Loss: 0.1529, Patience: 0\n",
      "Epoch 432/2000, Train Loss: 0.2107, Val Loss: 0.1535, Patience: 1\n",
      "Epoch 433/2000, Train Loss: 0.2109, Val Loss: 0.1551, Patience: 2\n",
      "Epoch 434/2000, Train Loss: 0.2149, Val Loss: 0.1563, Patience: 3\n",
      "Epoch 435/2000, Train Loss: 0.2124, Val Loss: 0.1567, Patience: 4\n",
      "Epoch 436/2000, Train Loss: 0.2160, Val Loss: 0.1532, Patience: 5\n",
      "Epoch 437/2000, Train Loss: 0.1984, Val Loss: 0.1554, Patience: 6\n",
      "Epoch 438/2000, Train Loss: 0.2076, Val Loss: 0.1542, Patience: 7\n",
      "Epoch 439/2000, Train Loss: 0.1974, Val Loss: 0.1537, Patience: 8\n",
      "Epoch 440/2000, Train Loss: 0.1974, Val Loss: 0.1536, Patience: 9\n",
      "Epoch 441/2000, Train Loss: 0.2166, Val Loss: 0.1550, Patience: 10\n",
      "Epoch 442/2000, Train Loss: 0.2171, Val Loss: 0.1537, Patience: 11\n",
      "Epoch 443/2000, Train Loss: 0.1960, Val Loss: 0.1542, Patience: 12\n",
      "Epoch 444/2000, Train Loss: 0.1987, Val Loss: 0.1538, Patience: 13\n",
      "Epoch 445/2000, Train Loss: 0.1917, Val Loss: 0.1511, Patience: 0\n",
      "Epoch 446/2000, Train Loss: 0.2019, Val Loss: 0.1519, Patience: 1\n",
      "Epoch 447/2000, Train Loss: 0.2034, Val Loss: 0.1550, Patience: 2\n",
      "Epoch 448/2000, Train Loss: 0.1952, Val Loss: 0.1541, Patience: 3\n",
      "Epoch 449/2000, Train Loss: 0.2149, Val Loss: 0.1532, Patience: 4\n",
      "Epoch 450/2000, Train Loss: 0.2154, Val Loss: 0.1521, Patience: 5\n",
      "Epoch 451/2000, Train Loss: 0.2011, Val Loss: 0.1554, Patience: 6\n",
      "Epoch 452/2000, Train Loss: 0.2147, Val Loss: 0.1539, Patience: 7\n",
      "Epoch 453/2000, Train Loss: 0.2009, Val Loss: 0.1546, Patience: 8\n",
      "Epoch 454/2000, Train Loss: 0.2096, Val Loss: 0.1523, Patience: 9\n",
      "Epoch 455/2000, Train Loss: 0.2093, Val Loss: 0.1534, Patience: 10\n",
      "Epoch 456/2000, Train Loss: 0.1896, Val Loss: 0.1515, Patience: 11\n",
      "Epoch 457/2000, Train Loss: 0.2027, Val Loss: 0.1523, Patience: 12\n",
      "Epoch 458/2000, Train Loss: 0.2007, Val Loss: 0.1506, Patience: 0\n",
      "Epoch 459/2000, Train Loss: 0.2163, Val Loss: 0.1510, Patience: 1\n",
      "Epoch 460/2000, Train Loss: 0.1952, Val Loss: 0.1508, Patience: 2\n",
      "Epoch 461/2000, Train Loss: 0.2120, Val Loss: 0.1513, Patience: 3\n",
      "Epoch 462/2000, Train Loss: 0.2077, Val Loss: 0.1514, Patience: 4\n",
      "Epoch 463/2000, Train Loss: 0.2239, Val Loss: 0.1559, Patience: 5\n",
      "Epoch 464/2000, Train Loss: 0.1974, Val Loss: 0.1558, Patience: 6\n",
      "Epoch 465/2000, Train Loss: 0.2202, Val Loss: 0.1540, Patience: 7\n",
      "Epoch 466/2000, Train Loss: 0.1953, Val Loss: 0.1565, Patience: 8\n",
      "Epoch 467/2000, Train Loss: 0.2027, Val Loss: 0.1520, Patience: 9\n",
      "Epoch 468/2000, Train Loss: 0.1914, Val Loss: 0.1549, Patience: 10\n",
      "Epoch 469/2000, Train Loss: 0.2019, Val Loss: 0.1508, Patience: 11\n",
      "Epoch 470/2000, Train Loss: 0.2012, Val Loss: 0.1505, Patience: 0\n",
      "Epoch 471/2000, Train Loss: 0.1869, Val Loss: 0.1495, Patience: 0\n",
      "Epoch 472/2000, Train Loss: 0.2122, Val Loss: 0.1512, Patience: 1\n",
      "Epoch 473/2000, Train Loss: 0.1972, Val Loss: 0.1491, Patience: 0\n",
      "Epoch 474/2000, Train Loss: 0.2055, Val Loss: 0.1493, Patience: 1\n",
      "Epoch 475/2000, Train Loss: 0.1863, Val Loss: 0.1502, Patience: 2\n",
      "Epoch 476/2000, Train Loss: 0.1876, Val Loss: 0.1481, Patience: 0\n",
      "Epoch 477/2000, Train Loss: 0.2058, Val Loss: 0.1498, Patience: 1\n",
      "Epoch 478/2000, Train Loss: 0.1973, Val Loss: 0.1473, Patience: 0\n",
      "Epoch 479/2000, Train Loss: 0.1865, Val Loss: 0.1471, Patience: 0\n",
      "Epoch 480/2000, Train Loss: 0.1927, Val Loss: 0.1479, Patience: 1\n",
      "Epoch 481/2000, Train Loss: 0.2067, Val Loss: 0.1498, Patience: 2\n",
      "Epoch 482/2000, Train Loss: 0.2071, Val Loss: 0.1470, Patience: 0\n",
      "Epoch 483/2000, Train Loss: 0.2016, Val Loss: 0.1468, Patience: 0\n",
      "Epoch 484/2000, Train Loss: 0.2032, Val Loss: 0.1492, Patience: 1\n",
      "Epoch 485/2000, Train Loss: 0.1997, Val Loss: 0.1481, Patience: 2\n",
      "Epoch 486/2000, Train Loss: 0.1785, Val Loss: 0.1477, Patience: 3\n",
      "Epoch 487/2000, Train Loss: 0.2036, Val Loss: 0.1496, Patience: 4\n",
      "Epoch 488/2000, Train Loss: 0.1880, Val Loss: 0.1500, Patience: 5\n",
      "Epoch 489/2000, Train Loss: 0.1944, Val Loss: 0.1496, Patience: 6\n",
      "Epoch 490/2000, Train Loss: 0.2042, Val Loss: 0.1490, Patience: 7\n",
      "Epoch 491/2000, Train Loss: 0.1862, Val Loss: 0.1486, Patience: 8\n",
      "Epoch 492/2000, Train Loss: 0.1837, Val Loss: 0.1490, Patience: 9\n",
      "Epoch 493/2000, Train Loss: 0.1879, Val Loss: 0.1465, Patience: 0\n",
      "Epoch 494/2000, Train Loss: 0.2031, Val Loss: 0.1482, Patience: 1\n",
      "Epoch 495/2000, Train Loss: 0.1993, Val Loss: 0.1469, Patience: 2\n",
      "Epoch 496/2000, Train Loss: 0.1904, Val Loss: 0.1453, Patience: 0\n",
      "Epoch 497/2000, Train Loss: 0.1809, Val Loss: 0.1434, Patience: 0\n",
      "Epoch 498/2000, Train Loss: 0.1846, Val Loss: 0.1444, Patience: 1\n",
      "Epoch 499/2000, Train Loss: 0.1980, Val Loss: 0.1439, Patience: 2\n",
      "Epoch 500/2000, Train Loss: 0.1918, Val Loss: 0.1424, Patience: 0\n",
      "Epoch 501/2000, Train Loss: 0.1891, Val Loss: 0.1462, Patience: 1\n",
      "Epoch 502/2000, Train Loss: 0.2008, Val Loss: 0.1495, Patience: 2\n",
      "Epoch 503/2000, Train Loss: 0.2033, Val Loss: 0.1471, Patience: 3\n",
      "Epoch 504/2000, Train Loss: 0.1923, Val Loss: 0.1461, Patience: 4\n",
      "Epoch 505/2000, Train Loss: 0.2016, Val Loss: 0.1496, Patience: 5\n",
      "Epoch 506/2000, Train Loss: 0.1984, Val Loss: 0.1470, Patience: 6\n",
      "Epoch 507/2000, Train Loss: 0.1883, Val Loss: 0.1497, Patience: 7\n",
      "Epoch 508/2000, Train Loss: 0.1974, Val Loss: 0.1451, Patience: 8\n",
      "Epoch 509/2000, Train Loss: 0.1847, Val Loss: 0.1453, Patience: 9\n",
      "Epoch 510/2000, Train Loss: 0.1976, Val Loss: 0.1452, Patience: 10\n",
      "Epoch 511/2000, Train Loss: 0.1834, Val Loss: 0.1466, Patience: 11\n",
      "Epoch 512/2000, Train Loss: 0.2040, Val Loss: 0.1422, Patience: 0\n",
      "Epoch 513/2000, Train Loss: 0.1867, Val Loss: 0.1407, Patience: 0\n",
      "Epoch 514/2000, Train Loss: 0.1922, Val Loss: 0.1437, Patience: 1\n",
      "Epoch 515/2000, Train Loss: 0.1923, Val Loss: 0.1456, Patience: 2\n",
      "Epoch 516/2000, Train Loss: 0.1947, Val Loss: 0.1443, Patience: 3\n",
      "Epoch 517/2000, Train Loss: 0.1797, Val Loss: 0.1459, Patience: 4\n",
      "Epoch 518/2000, Train Loss: 0.1859, Val Loss: 0.1463, Patience: 5\n",
      "Epoch 519/2000, Train Loss: 0.1837, Val Loss: 0.1456, Patience: 6\n",
      "Epoch 520/2000, Train Loss: 0.1959, Val Loss: 0.1440, Patience: 7\n",
      "Epoch 521/2000, Train Loss: 0.1701, Val Loss: 0.1441, Patience: 8\n",
      "Epoch 522/2000, Train Loss: 0.1845, Val Loss: 0.1442, Patience: 9\n",
      "Epoch 523/2000, Train Loss: 0.1930, Val Loss: 0.1442, Patience: 10\n",
      "Epoch 524/2000, Train Loss: 0.2195, Val Loss: 0.1434, Patience: 11\n",
      "Epoch 525/2000, Train Loss: 0.1877, Val Loss: 0.1442, Patience: 12\n",
      "Epoch 526/2000, Train Loss: 0.1937, Val Loss: 0.1462, Patience: 13\n",
      "Epoch 527/2000, Train Loss: 0.1670, Val Loss: 0.1431, Patience: 14\n",
      "Epoch 528/2000, Train Loss: 0.1780, Val Loss: 0.1435, Patience: 15\n",
      "Epoch 529/2000, Train Loss: 0.1722, Val Loss: 0.1437, Patience: 16\n",
      "Epoch 530/2000, Train Loss: 0.1836, Val Loss: 0.1464, Patience: 17\n",
      "Epoch 531/2000, Train Loss: 0.1929, Val Loss: 0.1423, Patience: 18\n",
      "Epoch 532/2000, Train Loss: 0.1931, Val Loss: 0.1455, Patience: 19\n",
      "Epoch 533/2000, Train Loss: 0.1708, Val Loss: 0.1404, Patience: 0\n",
      "Epoch 534/2000, Train Loss: 0.1870, Val Loss: 0.1393, Patience: 0\n",
      "Epoch 535/2000, Train Loss: 0.1853, Val Loss: 0.1412, Patience: 1\n",
      "Epoch 536/2000, Train Loss: 0.1849, Val Loss: 0.1410, Patience: 2\n",
      "Epoch 537/2000, Train Loss: 0.1844, Val Loss: 0.1434, Patience: 3\n",
      "Epoch 538/2000, Train Loss: 0.1857, Val Loss: 0.1415, Patience: 4\n",
      "Epoch 539/2000, Train Loss: 0.1834, Val Loss: 0.1445, Patience: 5\n",
      "Epoch 540/2000, Train Loss: 0.1746, Val Loss: 0.1392, Patience: 0\n",
      "Epoch 541/2000, Train Loss: 0.1742, Val Loss: 0.1401, Patience: 1\n",
      "Epoch 542/2000, Train Loss: 0.1969, Val Loss: 0.1433, Patience: 2\n",
      "Epoch 543/2000, Train Loss: 0.1810, Val Loss: 0.1433, Patience: 3\n",
      "Epoch 544/2000, Train Loss: 0.1739, Val Loss: 0.1434, Patience: 4\n",
      "Epoch 545/2000, Train Loss: 0.1909, Val Loss: 0.1419, Patience: 5\n",
      "Epoch 546/2000, Train Loss: 0.2031, Val Loss: 0.1406, Patience: 6\n",
      "Epoch 547/2000, Train Loss: 0.1739, Val Loss: 0.1404, Patience: 7\n",
      "Epoch 548/2000, Train Loss: 0.1761, Val Loss: 0.1409, Patience: 8\n",
      "Epoch 549/2000, Train Loss: 0.1710, Val Loss: 0.1381, Patience: 0\n",
      "Epoch 550/2000, Train Loss: 0.1826, Val Loss: 0.1415, Patience: 1\n",
      "Epoch 551/2000, Train Loss: 0.1866, Val Loss: 0.1410, Patience: 2\n",
      "Epoch 552/2000, Train Loss: 0.1906, Val Loss: 0.1402, Patience: 3\n",
      "Epoch 553/2000, Train Loss: 0.1703, Val Loss: 0.1418, Patience: 4\n",
      "Epoch 554/2000, Train Loss: 0.1909, Val Loss: 0.1429, Patience: 5\n",
      "Epoch 555/2000, Train Loss: 0.1991, Val Loss: 0.1436, Patience: 6\n",
      "Epoch 556/2000, Train Loss: 0.1671, Val Loss: 0.1408, Patience: 7\n",
      "Epoch 557/2000, Train Loss: 0.1809, Val Loss: 0.1387, Patience: 8\n",
      "Epoch 558/2000, Train Loss: 0.1805, Val Loss: 0.1436, Patience: 9\n",
      "Epoch 559/2000, Train Loss: 0.1778, Val Loss: 0.1431, Patience: 10\n",
      "Epoch 560/2000, Train Loss: 0.1849, Val Loss: 0.1409, Patience: 11\n",
      "Epoch 561/2000, Train Loss: 0.1744, Val Loss: 0.1364, Patience: 0\n",
      "Epoch 562/2000, Train Loss: 0.1645, Val Loss: 0.1371, Patience: 1\n",
      "Epoch 563/2000, Train Loss: 0.1803, Val Loss: 0.1384, Patience: 2\n",
      "Epoch 564/2000, Train Loss: 0.1852, Val Loss: 0.1372, Patience: 3\n",
      "Epoch 565/2000, Train Loss: 0.1779, Val Loss: 0.1387, Patience: 4\n",
      "Epoch 566/2000, Train Loss: 0.1866, Val Loss: 0.1388, Patience: 5\n",
      "Epoch 567/2000, Train Loss: 0.1739, Val Loss: 0.1370, Patience: 6\n",
      "Epoch 568/2000, Train Loss: 0.1666, Val Loss: 0.1364, Patience: 0\n",
      "Epoch 569/2000, Train Loss: 0.1756, Val Loss: 0.1350, Patience: 0\n",
      "Epoch 570/2000, Train Loss: 0.1792, Val Loss: 0.1387, Patience: 1\n",
      "Epoch 571/2000, Train Loss: 0.1757, Val Loss: 0.1416, Patience: 2\n",
      "Epoch 572/2000, Train Loss: 0.1643, Val Loss: 0.1362, Patience: 3\n",
      "Epoch 573/2000, Train Loss: 0.1615, Val Loss: 0.1368, Patience: 4\n",
      "Epoch 574/2000, Train Loss: 0.1801, Val Loss: 0.1346, Patience: 0\n",
      "Epoch 575/2000, Train Loss: 0.1616, Val Loss: 0.1361, Patience: 1\n",
      "Epoch 576/2000, Train Loss: 0.1673, Val Loss: 0.1357, Patience: 2\n",
      "Epoch 577/2000, Train Loss: 0.1732, Val Loss: 0.1412, Patience: 3\n",
      "Epoch 578/2000, Train Loss: 0.1794, Val Loss: 0.1363, Patience: 4\n",
      "Epoch 579/2000, Train Loss: 0.1760, Val Loss: 0.1342, Patience: 0\n",
      "Epoch 580/2000, Train Loss: 0.1698, Val Loss: 0.1367, Patience: 1\n",
      "Epoch 581/2000, Train Loss: 0.1680, Val Loss: 0.1353, Patience: 2\n",
      "Epoch 582/2000, Train Loss: 0.1789, Val Loss: 0.1372, Patience: 3\n",
      "Epoch 583/2000, Train Loss: 0.1888, Val Loss: 0.1365, Patience: 4\n",
      "Epoch 584/2000, Train Loss: 0.1831, Val Loss: 0.1334, Patience: 0\n",
      "Epoch 585/2000, Train Loss: 0.1874, Val Loss: 0.1378, Patience: 1\n",
      "Epoch 586/2000, Train Loss: 0.1741, Val Loss: 0.1351, Patience: 2\n",
      "Epoch 587/2000, Train Loss: 0.1799, Val Loss: 0.1334, Patience: 3\n",
      "Epoch 588/2000, Train Loss: 0.1731, Val Loss: 0.1312, Patience: 0\n",
      "Epoch 589/2000, Train Loss: 0.1651, Val Loss: 0.1355, Patience: 1\n",
      "Epoch 590/2000, Train Loss: 0.1632, Val Loss: 0.1364, Patience: 2\n",
      "Epoch 591/2000, Train Loss: 0.1759, Val Loss: 0.1341, Patience: 3\n",
      "Epoch 592/2000, Train Loss: 0.1668, Val Loss: 0.1327, Patience: 4\n",
      "Epoch 593/2000, Train Loss: 0.1673, Val Loss: 0.1337, Patience: 5\n",
      "Epoch 594/2000, Train Loss: 0.1688, Val Loss: 0.1320, Patience: 6\n",
      "Epoch 595/2000, Train Loss: 0.1849, Val Loss: 0.1373, Patience: 7\n",
      "Epoch 596/2000, Train Loss: 0.1683, Val Loss: 0.1334, Patience: 8\n",
      "Epoch 597/2000, Train Loss: 0.1717, Val Loss: 0.1311, Patience: 0\n",
      "Epoch 598/2000, Train Loss: 0.1679, Val Loss: 0.1288, Patience: 0\n",
      "Epoch 599/2000, Train Loss: 0.1659, Val Loss: 0.1319, Patience: 1\n",
      "Epoch 600/2000, Train Loss: 0.1735, Val Loss: 0.1322, Patience: 2\n",
      "Epoch 601/2000, Train Loss: 0.1741, Val Loss: 0.1331, Patience: 3\n",
      "Epoch 602/2000, Train Loss: 0.1694, Val Loss: 0.1336, Patience: 4\n",
      "Epoch 603/2000, Train Loss: 0.1698, Val Loss: 0.1319, Patience: 5\n",
      "Epoch 604/2000, Train Loss: 0.1666, Val Loss: 0.1301, Patience: 6\n",
      "Epoch 605/2000, Train Loss: 0.1603, Val Loss: 0.1320, Patience: 7\n",
      "Epoch 606/2000, Train Loss: 0.1697, Val Loss: 0.1315, Patience: 8\n",
      "Epoch 607/2000, Train Loss: 0.1645, Val Loss: 0.1304, Patience: 9\n",
      "Epoch 608/2000, Train Loss: 0.1862, Val Loss: 0.1324, Patience: 10\n",
      "Epoch 609/2000, Train Loss: 0.1686, Val Loss: 0.1314, Patience: 11\n",
      "Epoch 610/2000, Train Loss: 0.1638, Val Loss: 0.1331, Patience: 12\n",
      "Epoch 611/2000, Train Loss: 0.1842, Val Loss: 0.1335, Patience: 13\n",
      "Epoch 612/2000, Train Loss: 0.1556, Val Loss: 0.1337, Patience: 14\n",
      "Epoch 613/2000, Train Loss: 0.1643, Val Loss: 0.1347, Patience: 15\n",
      "Epoch 614/2000, Train Loss: 0.1646, Val Loss: 0.1348, Patience: 16\n",
      "Epoch 615/2000, Train Loss: 0.1735, Val Loss: 0.1347, Patience: 17\n",
      "Epoch 616/2000, Train Loss: 0.1826, Val Loss: 0.1327, Patience: 18\n",
      "Epoch 617/2000, Train Loss: 0.1573, Val Loss: 0.1317, Patience: 19\n",
      "Epoch 618/2000, Train Loss: 0.1634, Val Loss: 0.1352, Patience: 20\n",
      "Epoch 619/2000, Train Loss: 0.1754, Val Loss: 0.1329, Patience: 21\n",
      "Epoch 620/2000, Train Loss: 0.1787, Val Loss: 0.1335, Patience: 22\n",
      "Epoch 621/2000, Train Loss: 0.1746, Val Loss: 0.1302, Patience: 23\n",
      "Epoch 622/2000, Train Loss: 0.1511, Val Loss: 0.1289, Patience: 24\n",
      "Epoch 623/2000, Train Loss: 0.1529, Val Loss: 0.1302, Patience: 25\n",
      "Epoch 624/2000, Train Loss: 0.1774, Val Loss: 0.1320, Patience: 26\n",
      "Epoch 625/2000, Train Loss: 0.1673, Val Loss: 0.1310, Patience: 27\n",
      "Epoch 626/2000, Train Loss: 0.1622, Val Loss: 0.1285, Patience: 0\n",
      "Epoch 627/2000, Train Loss: 0.1684, Val Loss: 0.1292, Patience: 1\n",
      "Epoch 628/2000, Train Loss: 0.1738, Val Loss: 0.1301, Patience: 2\n",
      "Epoch 629/2000, Train Loss: 0.1637, Val Loss: 0.1305, Patience: 3\n",
      "Epoch 630/2000, Train Loss: 0.1563, Val Loss: 0.1330, Patience: 4\n",
      "Epoch 631/2000, Train Loss: 0.1603, Val Loss: 0.1343, Patience: 5\n",
      "Epoch 632/2000, Train Loss: 0.1584, Val Loss: 0.1312, Patience: 6\n",
      "Epoch 633/2000, Train Loss: 0.1736, Val Loss: 0.1318, Patience: 7\n",
      "Epoch 634/2000, Train Loss: 0.1788, Val Loss: 0.1298, Patience: 8\n",
      "Epoch 635/2000, Train Loss: 0.1661, Val Loss: 0.1291, Patience: 9\n",
      "Epoch 636/2000, Train Loss: 0.1593, Val Loss: 0.1287, Patience: 10\n",
      "Epoch 637/2000, Train Loss: 0.1589, Val Loss: 0.1254, Patience: 0\n",
      "Epoch 638/2000, Train Loss: 0.1729, Val Loss: 0.1285, Patience: 1\n",
      "Epoch 639/2000, Train Loss: 0.1642, Val Loss: 0.1293, Patience: 2\n",
      "Epoch 640/2000, Train Loss: 0.1586, Val Loss: 0.1291, Patience: 3\n",
      "Epoch 641/2000, Train Loss: 0.1551, Val Loss: 0.1247, Patience: 0\n",
      "Epoch 642/2000, Train Loss: 0.1527, Val Loss: 0.1310, Patience: 1\n",
      "Epoch 643/2000, Train Loss: 0.1694, Val Loss: 0.1302, Patience: 2\n",
      "Epoch 644/2000, Train Loss: 0.1532, Val Loss: 0.1285, Patience: 3\n",
      "Epoch 645/2000, Train Loss: 0.1592, Val Loss: 0.1289, Patience: 4\n",
      "Epoch 646/2000, Train Loss: 0.1435, Val Loss: 0.1278, Patience: 5\n",
      "Epoch 647/2000, Train Loss: 0.1619, Val Loss: 0.1316, Patience: 6\n",
      "Epoch 648/2000, Train Loss: 0.1491, Val Loss: 0.1267, Patience: 7\n",
      "Epoch 649/2000, Train Loss: 0.1622, Val Loss: 0.1270, Patience: 8\n",
      "Epoch 650/2000, Train Loss: 0.1583, Val Loss: 0.1284, Patience: 9\n",
      "Epoch 651/2000, Train Loss: 0.1611, Val Loss: 0.1255, Patience: 10\n",
      "Epoch 652/2000, Train Loss: 0.1672, Val Loss: 0.1276, Patience: 11\n",
      "Epoch 653/2000, Train Loss: 0.1589, Val Loss: 0.1275, Patience: 12\n",
      "Epoch 654/2000, Train Loss: 0.1598, Val Loss: 0.1253, Patience: 13\n",
      "Epoch 655/2000, Train Loss: 0.1564, Val Loss: 0.1236, Patience: 0\n",
      "Epoch 656/2000, Train Loss: 0.1601, Val Loss: 0.1247, Patience: 1\n",
      "Epoch 657/2000, Train Loss: 0.1708, Val Loss: 0.1261, Patience: 2\n",
      "Epoch 658/2000, Train Loss: 0.1602, Val Loss: 0.1267, Patience: 3\n",
      "Epoch 659/2000, Train Loss: 0.1645, Val Loss: 0.1264, Patience: 4\n",
      "Epoch 660/2000, Train Loss: 0.1486, Val Loss: 0.1287, Patience: 5\n",
      "Epoch 661/2000, Train Loss: 0.1482, Val Loss: 0.1289, Patience: 6\n",
      "Epoch 662/2000, Train Loss: 0.1657, Val Loss: 0.1261, Patience: 7\n",
      "Epoch 663/2000, Train Loss: 0.1593, Val Loss: 0.1263, Patience: 8\n",
      "Epoch 664/2000, Train Loss: 0.1518, Val Loss: 0.1276, Patience: 9\n",
      "Epoch 665/2000, Train Loss: 0.1504, Val Loss: 0.1279, Patience: 10\n",
      "Epoch 666/2000, Train Loss: 0.1496, Val Loss: 0.1301, Patience: 11\n",
      "Epoch 667/2000, Train Loss: 0.1716, Val Loss: 0.1343, Patience: 12\n",
      "Epoch 668/2000, Train Loss: 0.1551, Val Loss: 0.1274, Patience: 13\n",
      "Epoch 669/2000, Train Loss: 0.1643, Val Loss: 0.1271, Patience: 14\n",
      "Epoch 670/2000, Train Loss: 0.1505, Val Loss: 0.1270, Patience: 15\n",
      "Epoch 671/2000, Train Loss: 0.1676, Val Loss: 0.1254, Patience: 16\n",
      "Epoch 672/2000, Train Loss: 0.1590, Val Loss: 0.1263, Patience: 17\n",
      "Epoch 673/2000, Train Loss: 0.1621, Val Loss: 0.1262, Patience: 18\n",
      "Epoch 674/2000, Train Loss: 0.1606, Val Loss: 0.1266, Patience: 19\n",
      "Epoch 675/2000, Train Loss: 0.1572, Val Loss: 0.1273, Patience: 20\n",
      "Epoch 676/2000, Train Loss: 0.1444, Val Loss: 0.1277, Patience: 21\n",
      "Epoch 677/2000, Train Loss: 0.1541, Val Loss: 0.1280, Patience: 22\n",
      "Epoch 678/2000, Train Loss: 0.1566, Val Loss: 0.1263, Patience: 23\n",
      "Epoch 679/2000, Train Loss: 0.1604, Val Loss: 0.1246, Patience: 24\n",
      "Epoch 680/2000, Train Loss: 0.1529, Val Loss: 0.1267, Patience: 25\n",
      "Epoch 681/2000, Train Loss: 0.1520, Val Loss: 0.1242, Patience: 26\n",
      "Epoch 682/2000, Train Loss: 0.1506, Val Loss: 0.1243, Patience: 27\n",
      "Epoch 683/2000, Train Loss: 0.1567, Val Loss: 0.1275, Patience: 28\n",
      "Epoch 684/2000, Train Loss: 0.1485, Val Loss: 0.1263, Patience: 29\n",
      "Epoch 685/2000, Train Loss: 0.1588, Val Loss: 0.1236, Patience: 30\n",
      "Epoch 686/2000, Train Loss: 0.1593, Val Loss: 0.1267, Patience: 31\n",
      "Epoch 687/2000, Train Loss: 0.1661, Val Loss: 0.1256, Patience: 32\n",
      "Epoch 688/2000, Train Loss: 0.1551, Val Loss: 0.1237, Patience: 33\n",
      "Epoch 689/2000, Train Loss: 0.1478, Val Loss: 0.1238, Patience: 34\n",
      "Epoch 690/2000, Train Loss: 0.1523, Val Loss: 0.1236, Patience: 0\n",
      "Epoch 691/2000, Train Loss: 0.1501, Val Loss: 0.1230, Patience: 0\n",
      "Epoch 692/2000, Train Loss: 0.1445, Val Loss: 0.1226, Patience: 0\n",
      "Epoch 693/2000, Train Loss: 0.1531, Val Loss: 0.1216, Patience: 0\n",
      "Epoch 694/2000, Train Loss: 0.1522, Val Loss: 0.1219, Patience: 1\n",
      "Epoch 695/2000, Train Loss: 0.1361, Val Loss: 0.1226, Patience: 2\n",
      "Epoch 696/2000, Train Loss: 0.1546, Val Loss: 0.1226, Patience: 3\n",
      "Epoch 697/2000, Train Loss: 0.1367, Val Loss: 0.1236, Patience: 4\n",
      "Epoch 698/2000, Train Loss: 0.1609, Val Loss: 0.1255, Patience: 5\n",
      "Epoch 699/2000, Train Loss: 0.1556, Val Loss: 0.1216, Patience: 0\n",
      "Epoch 700/2000, Train Loss: 0.1532, Val Loss: 0.1201, Patience: 0\n",
      "Epoch 701/2000, Train Loss: 0.1573, Val Loss: 0.1187, Patience: 0\n",
      "Epoch 702/2000, Train Loss: 0.1700, Val Loss: 0.1198, Patience: 1\n",
      "Epoch 703/2000, Train Loss: 0.1638, Val Loss: 0.1250, Patience: 2\n",
      "Epoch 704/2000, Train Loss: 0.1355, Val Loss: 0.1272, Patience: 3\n",
      "Epoch 705/2000, Train Loss: 0.1450, Val Loss: 0.1219, Patience: 4\n",
      "Epoch 706/2000, Train Loss: 0.1419, Val Loss: 0.1223, Patience: 5\n",
      "Epoch 707/2000, Train Loss: 0.1569, Val Loss: 0.1234, Patience: 6\n",
      "Epoch 708/2000, Train Loss: 0.1536, Val Loss: 0.1248, Patience: 7\n",
      "Epoch 709/2000, Train Loss: 0.1610, Val Loss: 0.1241, Patience: 8\n",
      "Epoch 710/2000, Train Loss: 0.1562, Val Loss: 0.1237, Patience: 9\n",
      "Epoch 711/2000, Train Loss: 0.1540, Val Loss: 0.1253, Patience: 10\n",
      "Epoch 712/2000, Train Loss: 0.1581, Val Loss: 0.1224, Patience: 11\n",
      "Epoch 713/2000, Train Loss: 0.1425, Val Loss: 0.1235, Patience: 12\n",
      "Epoch 714/2000, Train Loss: 0.1512, Val Loss: 0.1226, Patience: 13\n",
      "Epoch 715/2000, Train Loss: 0.1644, Val Loss: 0.1237, Patience: 14\n",
      "Epoch 716/2000, Train Loss: 0.1416, Val Loss: 0.1223, Patience: 15\n",
      "Epoch 717/2000, Train Loss: 0.1559, Val Loss: 0.1230, Patience: 16\n",
      "Epoch 718/2000, Train Loss: 0.1506, Val Loss: 0.1178, Patience: 0\n",
      "Epoch 719/2000, Train Loss: 0.1468, Val Loss: 0.1210, Patience: 1\n",
      "Epoch 720/2000, Train Loss: 0.1504, Val Loss: 0.1228, Patience: 2\n",
      "Epoch 721/2000, Train Loss: 0.1526, Val Loss: 0.1219, Patience: 3\n",
      "Epoch 722/2000, Train Loss: 0.1666, Val Loss: 0.1207, Patience: 4\n",
      "Epoch 723/2000, Train Loss: 0.1425, Val Loss: 0.1187, Patience: 5\n",
      "Epoch 724/2000, Train Loss: 0.1548, Val Loss: 0.1188, Patience: 6\n",
      "Epoch 725/2000, Train Loss: 0.1486, Val Loss: 0.1191, Patience: 7\n",
      "Epoch 726/2000, Train Loss: 0.1480, Val Loss: 0.1202, Patience: 8\n",
      "Epoch 727/2000, Train Loss: 0.1615, Val Loss: 0.1186, Patience: 9\n",
      "Epoch 728/2000, Train Loss: 0.1497, Val Loss: 0.1193, Patience: 10\n",
      "Epoch 729/2000, Train Loss: 0.1569, Val Loss: 0.1194, Patience: 11\n",
      "Epoch 730/2000, Train Loss: 0.1583, Val Loss: 0.1210, Patience: 12\n",
      "Epoch 731/2000, Train Loss: 0.1448, Val Loss: 0.1199, Patience: 13\n",
      "Epoch 732/2000, Train Loss: 0.1483, Val Loss: 0.1197, Patience: 14\n",
      "Epoch 733/2000, Train Loss: 0.1520, Val Loss: 0.1177, Patience: 0\n",
      "Epoch 734/2000, Train Loss: 0.1488, Val Loss: 0.1178, Patience: 1\n",
      "Epoch 735/2000, Train Loss: 0.1504, Val Loss: 0.1193, Patience: 2\n",
      "Epoch 736/2000, Train Loss: 0.1546, Val Loss: 0.1182, Patience: 3\n",
      "Epoch 737/2000, Train Loss: 0.1416, Val Loss: 0.1200, Patience: 4\n",
      "Epoch 738/2000, Train Loss: 0.1418, Val Loss: 0.1212, Patience: 5\n",
      "Epoch 739/2000, Train Loss: 0.1352, Val Loss: 0.1204, Patience: 6\n",
      "Epoch 740/2000, Train Loss: 0.1625, Val Loss: 0.1198, Patience: 7\n",
      "Epoch 741/2000, Train Loss: 0.1538, Val Loss: 0.1195, Patience: 8\n",
      "Epoch 742/2000, Train Loss: 0.1482, Val Loss: 0.1210, Patience: 9\n",
      "Epoch 743/2000, Train Loss: 0.1512, Val Loss: 0.1253, Patience: 10\n",
      "Epoch 744/2000, Train Loss: 0.1461, Val Loss: 0.1204, Patience: 11\n",
      "Epoch 745/2000, Train Loss: 0.1450, Val Loss: 0.1235, Patience: 12\n",
      "Epoch 746/2000, Train Loss: 0.1447, Val Loss: 0.1240, Patience: 13\n",
      "Epoch 747/2000, Train Loss: 0.1488, Val Loss: 0.1200, Patience: 14\n",
      "Epoch 748/2000, Train Loss: 0.1443, Val Loss: 0.1203, Patience: 15\n",
      "Epoch 749/2000, Train Loss: 0.1434, Val Loss: 0.1194, Patience: 16\n",
      "Epoch 750/2000, Train Loss: 0.1414, Val Loss: 0.1217, Patience: 17\n",
      "Epoch 751/2000, Train Loss: 0.1365, Val Loss: 0.1200, Patience: 18\n",
      "Epoch 752/2000, Train Loss: 0.1552, Val Loss: 0.1214, Patience: 19\n",
      "Epoch 753/2000, Train Loss: 0.1412, Val Loss: 0.1206, Patience: 20\n",
      "Epoch 754/2000, Train Loss: 0.1402, Val Loss: 0.1221, Patience: 21\n",
      "Epoch 755/2000, Train Loss: 0.1514, Val Loss: 0.1253, Patience: 22\n",
      "Epoch 756/2000, Train Loss: 0.1465, Val Loss: 0.1226, Patience: 23\n",
      "Epoch 757/2000, Train Loss: 0.1457, Val Loss: 0.1224, Patience: 24\n",
      "Epoch 758/2000, Train Loss: 0.1481, Val Loss: 0.1215, Patience: 25\n",
      "Epoch 759/2000, Train Loss: 0.1441, Val Loss: 0.1201, Patience: 26\n",
      "Epoch 760/2000, Train Loss: 0.1291, Val Loss: 0.1178, Patience: 27\n",
      "Epoch 761/2000, Train Loss: 0.1476, Val Loss: 0.1181, Patience: 28\n",
      "Epoch 762/2000, Train Loss: 0.1536, Val Loss: 0.1193, Patience: 29\n",
      "Epoch 763/2000, Train Loss: 0.1416, Val Loss: 0.1198, Patience: 30\n",
      "Epoch 764/2000, Train Loss: 0.1413, Val Loss: 0.1198, Patience: 31\n",
      "Epoch 765/2000, Train Loss: 0.1358, Val Loss: 0.1222, Patience: 32\n",
      "Epoch 766/2000, Train Loss: 0.1509, Val Loss: 0.1207, Patience: 33\n",
      "Epoch 767/2000, Train Loss: 0.1349, Val Loss: 0.1197, Patience: 34\n",
      "Epoch 768/2000, Train Loss: 0.1494, Val Loss: 0.1220, Patience: 35\n",
      "Epoch 769/2000, Train Loss: 0.1401, Val Loss: 0.1161, Patience: 0\n",
      "Epoch 770/2000, Train Loss: 0.1408, Val Loss: 0.1156, Patience: 0\n",
      "Epoch 771/2000, Train Loss: 0.1453, Val Loss: 0.1186, Patience: 1\n",
      "Epoch 772/2000, Train Loss: 0.1477, Val Loss: 0.1239, Patience: 2\n",
      "Epoch 773/2000, Train Loss: 0.1406, Val Loss: 0.1186, Patience: 3\n",
      "Epoch 774/2000, Train Loss: 0.1530, Val Loss: 0.1193, Patience: 4\n",
      "Epoch 775/2000, Train Loss: 0.1400, Val Loss: 0.1191, Patience: 5\n",
      "Epoch 776/2000, Train Loss: 0.1436, Val Loss: 0.1202, Patience: 6\n",
      "Epoch 777/2000, Train Loss: 0.1399, Val Loss: 0.1199, Patience: 7\n",
      "Epoch 778/2000, Train Loss: 0.1465, Val Loss: 0.1180, Patience: 8\n",
      "Epoch 779/2000, Train Loss: 0.1437, Val Loss: 0.1181, Patience: 9\n",
      "Epoch 780/2000, Train Loss: 0.1414, Val Loss: 0.1202, Patience: 10\n",
      "Epoch 781/2000, Train Loss: 0.1413, Val Loss: 0.1209, Patience: 11\n",
      "Epoch 782/2000, Train Loss: 0.1406, Val Loss: 0.1186, Patience: 12\n",
      "Epoch 783/2000, Train Loss: 0.1465, Val Loss: 0.1167, Patience: 13\n",
      "Epoch 784/2000, Train Loss: 0.1343, Val Loss: 0.1159, Patience: 14\n",
      "Epoch 785/2000, Train Loss: 0.1420, Val Loss: 0.1180, Patience: 15\n",
      "Epoch 786/2000, Train Loss: 0.1408, Val Loss: 0.1136, Patience: 0\n",
      "Epoch 787/2000, Train Loss: 0.1468, Val Loss: 0.1155, Patience: 1\n",
      "Epoch 788/2000, Train Loss: 0.1326, Val Loss: 0.1138, Patience: 2\n",
      "Epoch 789/2000, Train Loss: 0.1405, Val Loss: 0.1179, Patience: 3\n",
      "Epoch 790/2000, Train Loss: 0.1494, Val Loss: 0.1158, Patience: 4\n",
      "Epoch 791/2000, Train Loss: 0.1410, Val Loss: 0.1229, Patience: 5\n",
      "Epoch 792/2000, Train Loss: 0.1374, Val Loss: 0.1193, Patience: 6\n",
      "Epoch 793/2000, Train Loss: 0.1482, Val Loss: 0.1177, Patience: 7\n",
      "Epoch 794/2000, Train Loss: 0.1337, Val Loss: 0.1135, Patience: 0\n",
      "Epoch 795/2000, Train Loss: 0.2103, Val Loss: 0.1166, Patience: 1\n",
      "Epoch 796/2000, Train Loss: 0.1306, Val Loss: 0.1204, Patience: 2\n",
      "Epoch 797/2000, Train Loss: 0.1444, Val Loss: 0.1196, Patience: 3\n",
      "Epoch 798/2000, Train Loss: 0.1454, Val Loss: 0.1224, Patience: 4\n",
      "Epoch 799/2000, Train Loss: 0.1446, Val Loss: 0.1195, Patience: 5\n",
      "Epoch 800/2000, Train Loss: 0.1372, Val Loss: 0.1163, Patience: 6\n",
      "Epoch 801/2000, Train Loss: 0.1462, Val Loss: 0.1176, Patience: 7\n",
      "Epoch 802/2000, Train Loss: 0.1463, Val Loss: 0.1176, Patience: 8\n",
      "Epoch 803/2000, Train Loss: 0.1366, Val Loss: 0.1193, Patience: 9\n",
      "Epoch 804/2000, Train Loss: 0.1406, Val Loss: 0.1208, Patience: 10\n",
      "Epoch 805/2000, Train Loss: 0.1390, Val Loss: 0.1204, Patience: 11\n",
      "Epoch 806/2000, Train Loss: 0.1351, Val Loss: 0.1231, Patience: 12\n",
      "Epoch 807/2000, Train Loss: 0.1500, Val Loss: 0.1194, Patience: 13\n",
      "Epoch 808/2000, Train Loss: 0.1395, Val Loss: 0.1199, Patience: 14\n",
      "Epoch 809/2000, Train Loss: 0.1325, Val Loss: 0.1234, Patience: 15\n",
      "Epoch 810/2000, Train Loss: 0.1554, Val Loss: 0.1186, Patience: 16\n",
      "Epoch 811/2000, Train Loss: 0.1399, Val Loss: 0.1179, Patience: 17\n",
      "Epoch 812/2000, Train Loss: 0.1386, Val Loss: 0.1187, Patience: 18\n",
      "Epoch 813/2000, Train Loss: 0.1421, Val Loss: 0.1192, Patience: 19\n",
      "Epoch 814/2000, Train Loss: 0.1367, Val Loss: 0.1225, Patience: 20\n",
      "Epoch 815/2000, Train Loss: 0.1329, Val Loss: 0.1158, Patience: 21\n",
      "Epoch 816/2000, Train Loss: 0.1296, Val Loss: 0.1174, Patience: 22\n",
      "Epoch 817/2000, Train Loss: 0.1534, Val Loss: 0.1185, Patience: 23\n",
      "Epoch 818/2000, Train Loss: 0.1533, Val Loss: 0.1144, Patience: 24\n",
      "Epoch 819/2000, Train Loss: 0.1361, Val Loss: 0.1166, Patience: 25\n",
      "Epoch 820/2000, Train Loss: 0.1462, Val Loss: 0.1209, Patience: 26\n",
      "Epoch 821/2000, Train Loss: 0.1394, Val Loss: 0.1191, Patience: 27\n",
      "Epoch 822/2000, Train Loss: 0.1306, Val Loss: 0.1179, Patience: 28\n",
      "Epoch 823/2000, Train Loss: 0.1442, Val Loss: 0.1208, Patience: 29\n",
      "Epoch 824/2000, Train Loss: 0.1448, Val Loss: 0.1201, Patience: 30\n",
      "Epoch 825/2000, Train Loss: 0.1533, Val Loss: 0.1196, Patience: 31\n",
      "Epoch 826/2000, Train Loss: 0.1448, Val Loss: 0.1184, Patience: 32\n",
      "Epoch 827/2000, Train Loss: 0.1496, Val Loss: 0.1177, Patience: 33\n",
      "Epoch 828/2000, Train Loss: 0.1571, Val Loss: 0.1201, Patience: 34\n",
      "Epoch 829/2000, Train Loss: 0.1516, Val Loss: 0.1197, Patience: 35\n",
      "Epoch 830/2000, Train Loss: 0.1495, Val Loss: 0.1224, Patience: 36\n",
      "Epoch 831/2000, Train Loss: 0.1237, Val Loss: 0.1200, Patience: 37\n",
      "Epoch 832/2000, Train Loss: 0.1285, Val Loss: 0.1197, Patience: 38\n",
      "Epoch 833/2000, Train Loss: 0.1311, Val Loss: 0.1185, Patience: 39\n",
      "Epoch 834/2000, Train Loss: 0.1374, Val Loss: 0.1165, Patience: 40\n",
      "Epoch 835/2000, Train Loss: 0.1402, Val Loss: 0.1153, Patience: 41\n",
      "Epoch 836/2000, Train Loss: 0.1379, Val Loss: 0.1189, Patience: 42\n",
      "Epoch 837/2000, Train Loss: 0.1329, Val Loss: 0.1174, Patience: 43\n",
      "Epoch 838/2000, Train Loss: 0.1554, Val Loss: 0.1211, Patience: 44\n",
      "Epoch 839/2000, Train Loss: 0.1459, Val Loss: 0.1173, Patience: 45\n",
      "Epoch 840/2000, Train Loss: 0.1342, Val Loss: 0.1171, Patience: 46\n",
      "Epoch 841/2000, Train Loss: 0.1367, Val Loss: 0.1163, Patience: 47\n",
      "Epoch 842/2000, Train Loss: 0.1415, Val Loss: 0.1179, Patience: 48\n",
      "Epoch 843/2000, Train Loss: 0.1280, Val Loss: 0.1159, Patience: 49\n",
      "Epoch 844/2000, Train Loss: 0.1340, Val Loss: 0.1133, Patience: 0\n",
      "Epoch 845/2000, Train Loss: 0.1344, Val Loss: 0.1106, Patience: 0\n",
      "Epoch 846/2000, Train Loss: 0.1336, Val Loss: 0.1152, Patience: 1\n",
      "Epoch 847/2000, Train Loss: 0.1324, Val Loss: 0.1143, Patience: 2\n",
      "Epoch 848/2000, Train Loss: 0.1508, Val Loss: 0.1169, Patience: 3\n",
      "Epoch 849/2000, Train Loss: 0.1449, Val Loss: 0.1146, Patience: 4\n",
      "Epoch 850/2000, Train Loss: 0.1350, Val Loss: 0.1154, Patience: 5\n",
      "Epoch 851/2000, Train Loss: 0.1264, Val Loss: 0.1139, Patience: 6\n",
      "Epoch 852/2000, Train Loss: 0.1335, Val Loss: 0.1157, Patience: 7\n",
      "Epoch 853/2000, Train Loss: 0.1462, Val Loss: 0.1201, Patience: 8\n",
      "Epoch 854/2000, Train Loss: 0.1377, Val Loss: 0.1143, Patience: 9\n",
      "Epoch 855/2000, Train Loss: 0.1581, Val Loss: 0.1141, Patience: 10\n",
      "Epoch 856/2000, Train Loss: 0.1414, Val Loss: 0.1170, Patience: 11\n",
      "Epoch 857/2000, Train Loss: 0.1447, Val Loss: 0.1183, Patience: 12\n",
      "Epoch 858/2000, Train Loss: 0.1446, Val Loss: 0.1166, Patience: 13\n",
      "Epoch 859/2000, Train Loss: 0.1384, Val Loss: 0.1149, Patience: 14\n",
      "Epoch 860/2000, Train Loss: 0.1497, Val Loss: 0.1139, Patience: 15\n",
      "Epoch 861/2000, Train Loss: 0.1574, Val Loss: 0.1184, Patience: 16\n",
      "Epoch 862/2000, Train Loss: 0.1383, Val Loss: 0.1167, Patience: 17\n",
      "Epoch 863/2000, Train Loss: 0.1368, Val Loss: 0.1173, Patience: 18\n",
      "Epoch 864/2000, Train Loss: 0.1332, Val Loss: 0.1155, Patience: 19\n",
      "Epoch 865/2000, Train Loss: 0.1444, Val Loss: 0.1196, Patience: 20\n",
      "Epoch 866/2000, Train Loss: 0.1318, Val Loss: 0.1175, Patience: 21\n",
      "Epoch 867/2000, Train Loss: 0.1433, Val Loss: 0.1197, Patience: 22\n",
      "Epoch 868/2000, Train Loss: 0.1273, Val Loss: 0.1180, Patience: 23\n",
      "Epoch 869/2000, Train Loss: 0.1443, Val Loss: 0.1192, Patience: 24\n",
      "Epoch 870/2000, Train Loss: 0.1300, Val Loss: 0.1168, Patience: 25\n",
      "Epoch 871/2000, Train Loss: 0.1551, Val Loss: 0.1169, Patience: 26\n",
      "Epoch 872/2000, Train Loss: 0.1431, Val Loss: 0.1158, Patience: 27\n",
      "Epoch 873/2000, Train Loss: 0.1511, Val Loss: 0.1172, Patience: 28\n",
      "Epoch 874/2000, Train Loss: 0.1405, Val Loss: 0.1147, Patience: 29\n",
      "Epoch 875/2000, Train Loss: 0.1290, Val Loss: 0.1159, Patience: 30\n",
      "Epoch 876/2000, Train Loss: 0.1287, Val Loss: 0.1169, Patience: 31\n",
      "Epoch 877/2000, Train Loss: 0.1383, Val Loss: 0.1170, Patience: 32\n",
      "Epoch 878/2000, Train Loss: 0.1335, Val Loss: 0.1190, Patience: 33\n",
      "Epoch 879/2000, Train Loss: 0.1258, Val Loss: 0.1144, Patience: 34\n",
      "Epoch 880/2000, Train Loss: 0.1387, Val Loss: 0.1153, Patience: 35\n",
      "Epoch 881/2000, Train Loss: 0.1312, Val Loss: 0.1150, Patience: 36\n",
      "Epoch 882/2000, Train Loss: 0.1285, Val Loss: 0.1117, Patience: 37\n",
      "Epoch 883/2000, Train Loss: 0.1360, Val Loss: 0.1135, Patience: 38\n",
      "Epoch 884/2000, Train Loss: 0.1390, Val Loss: 0.1137, Patience: 39\n",
      "Epoch 885/2000, Train Loss: 0.1375, Val Loss: 0.1146, Patience: 40\n",
      "Epoch 886/2000, Train Loss: 0.1272, Val Loss: 0.1148, Patience: 41\n",
      "Epoch 887/2000, Train Loss: 0.1252, Val Loss: 0.1149, Patience: 42\n",
      "Epoch 888/2000, Train Loss: 0.1352, Val Loss: 0.1168, Patience: 43\n",
      "Epoch 889/2000, Train Loss: 0.1359, Val Loss: 0.1164, Patience: 44\n",
      "Epoch 890/2000, Train Loss: 0.1386, Val Loss: 0.1158, Patience: 45\n",
      "Epoch 891/2000, Train Loss: 0.1282, Val Loss: 0.1169, Patience: 46\n",
      "Epoch 892/2000, Train Loss: 0.1480, Val Loss: 0.1152, Patience: 47\n",
      "Epoch 893/2000, Train Loss: 0.1437, Val Loss: 0.1157, Patience: 48\n",
      "Epoch 894/2000, Train Loss: 0.1373, Val Loss: 0.1208, Patience: 49\n",
      "Early stopping after 895 epochs\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "num_epochs = 2000\n",
    "patience = 50\n",
    "best_val_loss = np.inf\n",
    "patience_counter = 0\n",
    "best_model = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    for inputs, labels in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels.unsqueeze(1).float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "    train_loss /= len(train_dataloader.dataset)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    val_loss = 0.0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_dataloader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.unsqueeze(1).float())\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "        val_loss /= len(val_dataloader.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f'Early stopping after {epoch + 1} epochs')\n",
    "                break\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Patience: {patience_counter}')\n",
    "\n",
    "torch.save(best_model, 'best_model.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9598\n",
      "F1 score: 0.9594\n",
      "Precision: 0.9760\n",
      "Recall: 0.9433\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "model.load_state_dict(torch.load('best_model.pt'))\n",
    "\n",
    "test_predictions = []\n",
    "test_labels = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader:\n",
    "        outputs = model(inputs)\n",
    "        predicted = torch.round(outputs)\n",
    "        test_predictions.extend(predicted.detach().cpu().numpy())\n",
    "        test_labels.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(test_labels, test_predictions)\n",
    "f1 = f1_score(test_labels, test_predictions)\n",
    "precision = precision_score(test_labels, test_predictions)\n",
    "recall = recall_score(test_labels, test_predictions)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'F1 score: {f1:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
